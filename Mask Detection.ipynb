{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d42c21d",
   "metadata": {},
   "source": [
    "# Download Dataset Directly From Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d54bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669c8018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading face-mask-dataset.zip to .\\face-mask-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 163M/163M [02:17<00:00, 1.25MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "md = \"https://www.kaggle.com/datasets/omkargurav/face-mask-dataset\"\n",
    "od.download(md,force = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eecefec",
   "metadata": {},
   "source": [
    "# Import The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26da164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a982c35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['without_mask', 'with_mask']\n",
      "{'without_mask': 0, 'with_mask': 1}\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "with_mask_imgs = os.listdir(r\"D:\\CodeClause\\Mask Detection Project\\face-mask-dataset\\data\\with_mask\")\n",
    "without_mask_imgs = os.listdir(r\"D:\\CodeClause\\Mask Detection Project\\face-mask-dataset\\data\\without_mask\")\n",
    "data_categories = os.listdir(r\"D:\\CodeClause\\Mask Detection Project\\face-mask-dataset\\data\")\n",
    "\n",
    "Labels = [i for i in range(len(data_categories))]\n",
    "Labels_dict= dict(zip(data_categories,Labels))\n",
    "\n",
    "print(data_categories)\n",
    "print(Labels_dict)\n",
    "print(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f421c5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3725"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(with_mask_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b889250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(without_mask_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a72e37",
   "metadata": {},
   "source": [
    "# Doing Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e4edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "all_labels = []\n",
    "\n",
    "for category in data_categories:\n",
    "    folder_path = os.path.join (r\"D:\\CodeClause\\Mask Detection Project\\face-mask-dataset\\data\", category)\n",
    "    img_names = os.listdir(folder_path)\n",
    "   \n",
    "    for img_name in img_names:\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread (img_path)\n",
    " \n",
    "        img_RGP = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_resized = cv2.resize(img_RGP, (128 , 128))\n",
    "        img_array = np.array(img_resized)\n",
    "        data.append(img_array)\n",
    "        all_labels.append(Labels_dict[category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78337a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data)\n",
    "x = np.reshape(x,(x.shape[0],128,128,3))\n",
    "y = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f33d9762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "616ab727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7553, 128, 128, 3)\n",
      "(7553,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ce0ffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac3f8072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[3825:3830]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabce593",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c7638c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe695a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(128,(3,3), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e6de3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec97120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train / 255\n",
    "\n",
    "X_test_scaled = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c33f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "152/152 [==============================] - 19s 64ms/step - loss: 0.5848 - accuracy: 0.7076 - val_loss: 0.4038 - val_accuracy: 0.8420\n",
      "Epoch 2/15\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.3583 - accuracy: 0.8585 - val_loss: 0.3015 - val_accuracy: 0.8834\n",
      "Epoch 3/15\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.3290 - accuracy: 0.8701 - val_loss: 0.2821 - val_accuracy: 0.8825\n",
      "Epoch 4/15\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.3103 - accuracy: 0.8699 - val_loss: 0.2842 - val_accuracy: 0.8875\n",
      "Epoch 5/15\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.2695 - accuracy: 0.8955 - val_loss: 0.2955 - val_accuracy: 0.8916\n",
      "Epoch 6/15\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.2715 - accuracy: 0.8918 - val_loss: 0.2829 - val_accuracy: 0.8743\n",
      "Epoch 7/15\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.2683 - accuracy: 0.8928 - val_loss: 0.2618 - val_accuracy: 0.8933\n",
      "Epoch 8/15\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.2406 - accuracy: 0.9040 - val_loss: 0.2576 - val_accuracy: 0.9007\n",
      "Epoch 9/15\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2275 - accuracy: 0.9059 - val_loss: 0.2559 - val_accuracy: 0.9065\n",
      "Epoch 10/15\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.2170 - accuracy: 0.9127 - val_loss: 0.2566 - val_accuracy: 0.8999\n",
      "Epoch 11/15\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.2228 - accuracy: 0.9110 - val_loss: 0.2445 - val_accuracy: 0.9065\n",
      "Epoch 12/15\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.1935 - accuracy: 0.9205 - val_loss: 0.2285 - val_accuracy: 0.9090\n",
      "Epoch 13/15\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.1669 - accuracy: 0.9354 - val_loss: 0.2479 - val_accuracy: 0.9074\n",
      "Epoch 14/15\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.1421 - accuracy: 0.9423 - val_loss: 0.2435 - val_accuracy: 0.9123\n",
      "Epoch 15/15\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.1311 - accuracy: 0.9454 - val_loss: 0.2511 - val_accuracy: 0.9148\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train, validation_split=0.2, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa85e0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 24ms/step - loss: 0.1924 - accuracy: 0.9385\n",
      "[0.192354217171669, 0.93845134973526]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test_scaled, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dedc028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Mask Detecion Model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Mask Detecion Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff0dd3",
   "metadata": {},
   "source": [
    "# Real Time Mask Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecbfcbaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "counter = 0\n",
    "haar = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "labels_dict = {1:\"Mask\", 0:\"No Mask\"}\n",
    "color = {1 : (0,255,0) , 0 : (0,0,255)}\n",
    "\n",
    "\n",
    "while(True):\n",
    "\n",
    "        ret , img = video.read()\n",
    "        imgRGP = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        faces = haar.detectMultiScale(imgRGP, scaleFactor=1.3, minNeighbors=5)\n",
    "        for x,y,w,h in faces:\n",
    "\n",
    "            \n",
    "            face_img = imgRGP[ y:y+w , x:x+w]\n",
    "            resized = cv2.resize(face_img,(128,128))\n",
    "            normalized = resized / 255\n",
    "            reshaped = np.reshape(normalized,(1 , 128 ,128 , 3))\n",
    "            result = model.predict(reshaped)\n",
    "            label = np.argmax(result , axis = 1)[0]\n",
    "            \n",
    "            cv2.rectangle(img,(x , y), (x+w,y+h), color[label],2)\n",
    "            cv2.rectangle(img,(x , y-40),(x+w,y), color[label],-1)\n",
    "            cv2.putText(img, labels_dict[label], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255),2)\n",
    "\n",
    "        cv2.imshow('LIVE', img)\n",
    "       \n",
    "\n",
    "        if cv2.waitKey(20) & 0xFF == ord('d'):\n",
    "            break\n",
    "\n",
    "\n",
    "video.release()   \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e09d4",
   "metadata": {},
   "source": [
    "# Mask Detecion From Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21d97e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('image5.JPG')\n",
    "\n",
    "rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "haar = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "faces = haar.detectMultiScale(rgb, scaleFactor=1.2, minNeighbors=2,flags=cv2.CASCADE_FIND_BIGGEST_OBJECT)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    face = rgb[y:y+h, x:x+w]\n",
    "    face_resized = cv2.resize(face, (128, 128)) \n",
    "    face_normalized = face_resized / 255\n",
    "    face_expanded = np.reshape(face_normalized,(1 , 128 ,128 , 3)) # Add a batch dimension\n",
    "\n",
    "    prediction = model.predict(face_expanded)\n",
    "\n",
    "    if prediction[0][0] > prediction[0][1]:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), thickness=2)\n",
    "        cv2.putText(img, 'No Mask', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), thickness=2)\n",
    "    else:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), thickness=2)\n",
    "        cv2.putText(img, 'Mask', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), thickness=2)\n",
    "\n",
    "cv2.imshow('Detected Faces', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f5f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
